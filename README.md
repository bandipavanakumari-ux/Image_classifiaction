# CIFAR-100 Image Classification â€” ANN vs CNN
### ğŸ“Œ Project Overview# Image_classifiaction
This project focuses on multi-class image classification using the CIFAR-100 dataset. The primary objective is to compare the performance of Artificial Neural Networks (ANN) and Convolutional Neural Networks (CNN) on a challenging 100-class RGB image dataset.

The project demonstrates why CNNs are more suitable than traditional fully connected networks for computer vision tasks and includes model training, evaluation, and visualization of correct and incorrect predictions.

## ğŸ¯ Objectives

- Perform 100-class image classification using CIFAR-100

- Compare ANN and CNN architectures on image data

- Evaluate model performance using accuracy and loss metrics

- Visualize correct and incorrect predictions

- Analyze model errors across fine-grained object categories

- Demonstrate best practices in deep learning for computer vision

## ğŸ“¦ Dataset
- CIFAR-100

- Total Images: 60,000

- Training Images: 50,000

- Test Images: 10,000

- Image Size: 32 Ã— 32 pixels

- Channels: 3 (RGB)

- Number of Classes: 100 (fine labels)

- Superclasses: 20 (coarse labels)

The dataset contains diverse object categories including animals, vehicles, household objects, plants, and people.

### Official Source:
https://www.cs.toronto.edu/~kriz/cifar.html

## ğŸ§  Models Implemented
### 1. Artificial Neural Network (ANN)

- Input: Flattened 32Ã—32Ã—3 images

- Fully connected dense layers

- ReLU activations

- Softmax output layer (100 classes)

### Purpose:
To establish a baseline and demonstrate limitations of fully connected networks for image data.

### 2. Convolutional Neural Network (CNN)

- Convolutional layers (Conv2D)

- MaxPooling layers

- Batch Normalization (optional)

- Dropout for regularization

- Fully connected classifier head

- Softmax output layer (100 classes)

### Purpose:
To leverage spatial feature learning for improved image classification performance.

## ğŸ”„ Data Preprocessing

- Normalize pixel values to range [0, 1]

- One-hot encode labels for softmax classification

- Flatten labels for evaluation and visualization

- Shuffle and batch data for efficient training

Example:

x_train = x_train.astype('float32') / 255.0
x_test  = x_test.astype('float32') / 255.0

y_train_one_hot = to_categorical(y_train, 100)
y_test_one_hot  = to_categorical(y_test, 100)

## ğŸ—ï¸ Project Structure

cifar100-ann-vs-cnn/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ (optional local dataset files)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ cifar100_data_exploration.ipynb
â”‚   â”œâ”€â”€ ann_model_training.ipynb
â”‚   â”œâ”€â”€ cnn_model_training.ipynb
â”‚   â””â”€â”€ visualization_and_error_analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ ann_model.py
â”‚   â”œâ”€â”€ cnn_model.py
â”‚   â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_curves.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â””â”€â”€ prediction_visualizations.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

## ğŸ“Š Evaluation Metrics

- Accuracy

- Training vs Validation Loss

- Training vs Validation Accuracy

- Visual inspection of correct and incorrect predictions

- Confusion matrix (optional for deeper analysis)

## ğŸ† Results Summary (Example â€” Replace with Your Actual Numbers)

Model	Test Accuracy	Observations

ANN	~20% â€“ 30%	Struggles due to loss of spatial information
CNN	~45% â€“ 65%+	Learns spatial features, significantly better performance

## ğŸ” Key Insights

- CNN significantly outperforms ANN on CIFAR-100 due to spatial feature learning.

- ANN fails to capture local patterns and spatial hierarchies in images.

- CNN learns hierarchical features such as edges, textures, and object parts.

- Misclassifications commonly occur between visually similar object categories.

- Model architecture plays a critical role in image classification performance.

## ğŸ§¾ Conclusion

- CNN is the preferred architecture for CIFAR-100 image classification.

- ANN provides a useful baseline but is not suitable for complex image data.

- The project demonstrates the importance of convolutional layers for computer vision tasks.

- This work reinforces best practices for deep learning on image datasets.

## ğŸ–¼ï¸ Prediction Visualization

The project includes visualization of correctly and incorrectly classified images, highlighting:

Correct predictions (green labels)

Incorrect predictions (red labels with predicted vs true class)

Model strengths and common failure cases
